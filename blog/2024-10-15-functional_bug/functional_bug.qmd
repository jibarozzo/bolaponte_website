---
title: "Catching the Functional <bug>"
author: "Bolívar Aponte Rolón"
date: today
description: "test"
#image: 
#image-alt: 
categories:
  - R
  - Quarto
  - tidyverse
#bibliography: references.bib
number-sections: true
number-depth: 2
execute: 
  eval: true
  echo: true
  

---

First draft
For the past couple of years I've been working on increasing my understanding R , it ecosystem and the various tools it has for supporting open and reproducible science. The need to understand this did not come out of learned best practices, I am a trained ecologist and evolutionary biologist (EEB), R and computer science tools are usually a means to answer the big questions in EEB, it came out of frustration with how knowledge was transferred in academia. More frequently than not, the way academics learn R, at least how I learned it and those around me did, was through trial by fire, that fire being term paper deadlines or thesis/dissertations, more like wildfires. Learning R and how to best use it is low on the list of priorities and submitting the paper or presentation abstract is the goal. "I'll clean up the code later" being the mantra. Famous last words before orphaning a repo. 

Pitfalls in the learning process led to absolute paths, nuking directories and freaking out at meetings because the code doesn't run on your colleague machine. The process of unlearning these practices and embracing reproducible environments, version control, `renv`, `.Rproj` and many more is liberating and rewarding. Yes, there is a little more forethought in the beginning of the project, but getting that simple T-test to run in someone's machine and not having any issues is worth it. This is old news for software developers, much less the case for biologists.

For me, the main reason to create code is my innate need to share and see others benefit from what little I learn. Additionally, creating rigorous science requires 

Second draft



For the past couple of years, I've been deepening my understanding of R—its ecosystem and the many tools it offers for supporting open and reproducible science. My journey didn’t stem from learning best practices. As a trained ecologist and evolutionary biologist (EEB), R and computational tools were primarily a means to answer the big questions in my field. But what really pushed me to dive deeper was frustration—specifically, with how knowledge is often transferred in academia.

More often than not, the way academics learn R, at least in my experience and among my peers, is through a kind of trial by fire—often fueled by term paper deadlines or the looming pressure of thesis and dissertation submissions. It’s more like learning in the middle of a wildfire, to be honest. Learning R (or any coding tool) takes a backseat to the immediate goal: submitting the paper or presentation abstract. The familiar mantra becomes, "I'll clean up the code later," but those end up being famous last words before orphaning a repository, incomplete and messy.

This chaotic learning process has predictable pitfalls. From absolute paths breaking code on a different machine to accidentally deleting entire directories and freaking out in meetings when code refuses to run on a colleague’s setup, I’ve seen it all (Jenny Bryan would burn everyone computers). But it was through these frustrations that I began to unlearn bad habits and embrace reproducibility. Unlearning requires constant effort. Tools like version control, `renv`, `.Rproj`, and others became liberating. Yes, they require a little more planning at the start of a project, but having code that runs seamlessly on another person's machine without issue? That’s priceless.

For software developers, this might sound like old news, but for many biologists, reproducibility is still an uphill battle. We’re more familiar with the thrill of analyzing data than the discipline of building reproducible environments.

Personally, my drive to write and share code comes from an innate need to help others benefit from the little I’ve learned. But more than that, creating rigorous and reproducible science isn’t just an academic exercise; it’s a moral compass. 

What have I learned? 

Lately, I've been taking *Programming in R* course by [Posit Academy](https://posit.co/products/enterprise/academy/) and learning functional programming concepts, which I highly recommend even if your a seasoned useR.  This has prompted me to refactor much of the code I've produce to be more maintainable and human. My main focus has been plot reproduction. Some of my code has hundreds of lines producing *ggplots* that can easily be turned into a function(s).  

Let's see some example of how to use `purr::map()` to automate plot generation. 

### Setup

```{r}
#| label: setup
#| eval: true
#| echo: true
#| message: false

library(tidyverse)
library(palmerpenguins)
```

The `tidyverse` meta package includes `ggplot` (plots generation), `purrr` (iteration), and `dplyr` (data wrangling) the three main packages we will be using. 
### The problem
Copy and paste code to produce plots.

```{r}
#| label: copy_plots
#| echo: true
#| warning: false
#| message: false

# Body mass vs. flipper length
penguins |>
    ggplot(aes(x = flipper_length_mm, y = body_mass_g, color = species)) +
    geom_point() +
    geom_smooth(method = lm, se = T, level = 0.95, na.rm = F) +
    labs(title = "Penguin Body mass (g) vs. Flipper length (mm)")

# Body mass vs. bill depth
penguins |>
    ggplot(aes(x = bill_depth_mm, y = body_mass_g, color = species)) +
    geom_point() +
    geom_smooth(method = lm, se = T, level = 0.95, na.rm = F) +
    labs(title = "Penguin Body mass (g) vs. Bill depth (mm)")

# Body mass vs. bill length
penguins |>
    ggplot(aes(x = bill_length_mm, y = body_mass_g, color = species)) +
    geom_point() +
    geom_smooth(method = lm, se = T, level = 0.95, na.rm = F) +
    labs(title = "Penguin Body mass (g) vs. Bill length (mm)")
```

Maybe with just three plots this isn't a big deal. It quickly becomes a hassle to keep track of when you have over a dozen variables and the plots are roughly the same that it's not worth writing a whole new chunk. I've omitted creating respective object for the plots, but that is how I would usually store them and call them throughout the analysis (e.g., bodymass_fliplen or something like that). Again, that quite fine in a small script of analysis.

### Now, how do we automate this?
