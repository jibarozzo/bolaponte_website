[
  {
    "objectID": "software/index.html",
    "href": "software/index.html",
    "title": "Software and Tools",
    "section": "",
    "text": "I develop and maintain several R packages and analysis tools for the research community, including:\n\nBRCore: An R package for core analysis workflows in microbial ecology.\ninterbrc-core-analysis: Analysis pipelines for the Bioenergy Research Center’s shared research objective to understand feedstock microbiomes.\nesipDMP: A premier in data management planning and stewardship.\nrateDMP: (Rust) An experimental tool for rating or evaluating Data Management Plans.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "2018 – 2024 Tulane University, Department of Ecology and Biology\n\nUniversity of Michigan – Ann Arbor - Major: Conservation Ecology\n\nUniversity of Puerto Rico – Rio Piedras\n\nMajor: Political Science (Magna Cum Laude)"
  },
  {
    "objectID": "cv/index.html#education",
    "href": "cv/index.html#education",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "2018 – 2024 Tulane University, Department of Ecology and Biology\n\nUniversity of Michigan – Ann Arbor - Major: Conservation Ecology\n\nUniversity of Puerto Rico – Rio Piedras\n\nMajor: Political Science (Magna Cum Laude)"
  },
  {
    "objectID": "cv/index.html#skills",
    "href": "cv/index.html#skills",
    "title": "Curriculum Vitae",
    "section": "\n Skills",
    "text": "Skills\n\n\n\n\n\n\n\n\nLeadership\nEffective communication, Decision-Making, Critical thinking, Team collaboration, Problem-solving, Adaptability\n\n\nInterpersonal Skills\nMentoring, Cross-functional collaboration, Team-building, Conflict resolution, Stakeholder communication\n\n\nProgramming/Interface\nR, Python, Bash, Rust, Nextflow, SQL, LaTex, Markdown\n\n\nData/Web Reporting\nQuarto, Shiny\n\n\nOS/Shell Experience\nLinux, PowerShell, WSL\n\n\nCloud/High-Performance Computing\nAWS, SLURM, BLAS library\n\n\nData Wrangling and Visualization\n\ntidyverse, ggplot2, Tableau\n\n\nVersion Control\nGit and GitHub\n\n\nBioinformatic Tools\nGATK, samtools, cutadapt, Trimmomatic, phyloseq and microeco"
  },
  {
    "objectID": "cv/index.html#peer-reviewed-publications-and-pre-prints",
    "href": "cv/index.html#peer-reviewed-publications-and-pre-prints",
    "title": "Curriculum Vitae",
    "section": "\n Peer-Reviewed Publications and Pre-Prints",
    "text": "Peer-Reviewed Publications and Pre-Prints\n\nDong, C. M., Aponte Rolón, B., Sullivan, J. K., Tataru, D., Deleon, M., Dennis, R., Dutton, S., Machado Perez, F. J., Montano, L., & Ferris, K. G. (2024, June 29). Short-term fluctuating and long-term divergent selection on sympatric Monkeyflowers: Insights from decade-spanning reciprocal transplants. https://doi.org/10.1101/2024.06.26.600870\nAponte Rolón, B., Arnold, A. E., Sánchez Juliá, M., & Van Bael, S. A. (2024). Evaluating endophyte‑rich leaves and leaf functional traits for protection of tropical trees against natural enemies. Functional Ecology, 1365–2435.14717. https://doi.org/10.1111/1365-2435.14717\nAponte Rolón, B., & Perfecto, I. (2023). Between two trees: Environmental effects of I. Micheliana and A. Latifolia on leaf litter ants in a coffee agroecosystem. Ecosphere, 14(2), e4442. https://doi.org/10.1002/ecs2.4442\n\nSchmitt, L., Aponte Rolón, B., & Perfecto, I. (2020). Evaluating community effects of a Keystone Ant, Azteca sericeasur, on Inga micheliana leaf litter decomposition in a shaded coffee agro‑ecosystem. Biotropica, 52(6), 1253–1261. https://doi.org/10.1111/btp.12833"
  },
  {
    "objectID": "cv/index.html#software-data",
    "href": "cv/index.html#software-data",
    "title": "Curriculum Vitae",
    "section": "\n Software & Data",
    "text": "Software & Data\n\n\nAponte Rolón, B., Blake, R. E., Berys, C., Gum, J., & Wood‑Charlson, E. M. (2025). esipDMP: Data Management for Success. https://doi.org/10.5281/ZENODO.17252143\n\nAponte Rolón, B., Kristy, B., & Benucci, G. (2025). BRCore: Provides a set of tools to process and analyze microbial data from Bioenergy Research Centers. Retrieved from https://github.com/germs-lab/BRCore. R package version 0.1.0, commit b3915756f8eef04947597359a2c365349c372a00.\nRieke, M., & Aponte Rolón, B. (2025). Nplyr: A grammar of nested data manipulation. Retrieved from https://jibarozzo.github.io/nplyr/. R package version 0.3.0."
  },
  {
    "objectID": "cv/index.html#other-publications",
    "href": "cv/index.html#other-publications",
    "title": "Curriculum Vitae",
    "section": "\n Other Publications",
    "text": "Other Publications\n\nAponte Rolón, B. (2023). High-Molecular-Weight SPRI-aided DNA extraction fro Mimulus MimulusMimulus * Mimulus Mimulus MimulusMimulusMimulus* (Phrymaceae) leaf tissue. dx.doi.org/10.17504/protocols.io.bp2l6xn8rlqe/v2\nPérez-Figueroa, O., & Aponte Rolón, B. (2020). Clashing Resilience: Competing Agendas for Recovery after the Puerto Rican Hurricanes • SftP Magazine. Science for the People Magazine, 23(1). https://magazine.scienceforthepeople.org/vol23-1/clashing-resilience-competing-agendas-for-recovery-after-the-puerto-rican-hurricanes/"
  },
  {
    "objectID": "cv/index.html#professional-experience",
    "href": "cv/index.html#professional-experience",
    "title": "Curriculum Vitae",
    "section": "\n Professional Experience",
    "text": "Professional Experience\nPost-Doctoral Research Associate Jan-2025-Present\nDepartment of Agricultural and Biosystems Engineering, Iowa State University, Ames, IA\n\n\nDeveloped high-throughput, reproducible pipelines for large-scale microbiome analysis, enabling robust identification of core and non-core microbial communities across multiple Bioenergy Research Centers (BRCs) using R, parallel computing, and high-performance cluster resources.\n\nAuthor and maintainer of the “BRCore” R package. Implemented novel methods for core microbiome extraction based on Bray-Curtis dissimilarity and abundance-occupancy modeling, now used as a foundational tool within the Inter-BRC Microbiome project.\n\nEnabled cross-center, cross-crop comparative analyses by standardizing data processing, quality control, and statistical workflows (e.g., ordinations, dbRDA), directly supporting multi-institutional collaboration and increasing analytical consistency.\n\nProduced publication-ready visualizations and summary statistics that revealed robust patterns of core microbial taxa and their ecological drivers, informing both experimental design and biological interpretation within the BRC network.\n\nDemonstrated the ecological significance of core taxa, quantifying their contribution to community dissimilarity and highlighting deterministic versus stochastic assembly processes in plant-microbe interactions.\n\nEmpowered team members and collaborators by providing well-documented, reusable code, comprehensive reports, and training, thereby enhancing the overall reproducibility, transparency, and impact of the research program.\n\nAccelerated research outputs and scientific communication, delivering actionable insights and high-quality figures/tables for manuscripts, presentations, and stakeholder reports in the field of microbial ecology and bioinformatics.\n\nTechnical Lead & Platform Architect Jan-2025-Present\nEarth Science Information Partners - Data Stewardship Committee, Severna Park, MD\n\n\nTechnical Lead & Platform Architect for ESIP’s “esipDMP: Data Management for Success”, defined the Quarto-based site architecture and information model, organizing content into clear domains with sidebar search, global TOC, and page navigation for discoverability.\n\nBuilt a clear, efficient front-end on Bootswatch: customized CSS/SCSS and HTML components to establish consistent layout, typography, and reusable patterns that scale for an open-source community of data practitioners.\n\nOperationalized, contributor-friendly workflows and deployment: architected a GitHub Pages publishing pipeline with deterministic URLs, standardized outputs, and repo-actions/issue templates to streamline PRs and community feedback.\n\nLed cross-community collaboration (ESIP Data Stewardship Committee), establishing review pathways and content stewardship practices while maintaining a continuously deployed high-signal community-owned public resource.\n\nStandardized navigation and content templates to reduce contributor friction and maintenance overhead, enabling incremental, peer-reviewed additions while preserving a stable, version-controlled site foundation.\n\nData Scientist 2018-2024\nDepartment of Ecology and Evolutionary Biology, Tulane University, New Orleans, LA\n\n\nOwned experimental design, data collection, analysis and interpretation for 3 research projects focused on understanding the interactions of fungal symbionts, and host-associated genes, resulting in production of 2 peer-reviewed articles.\n\nDeveloped R, Python, and Bash modules to process genomic and metagenomic data by applying the DADA2 and USEARCH algorithms for novel fungal discovery.\n\nApplied GLMMs, ANOVAs, and clustering algorithms (PCA, LDA) in R to analyze biological datasets or 3 research projects.\nExecuted processing workflows via SLURM on a HPC cluster environment.\n\nCollaborated with a team of 6+ members to develop workflows for troubleshooting genomic data processing pipelines with GATK tools; the resulting workflow is hosted on GitHub.\n\nEnhanced R package function features to handle additional diversity measures; forked and submitted pull request to the open-source “mirlyn” package.\n\nEnsured data integrity and reproducibility of statistical analyses; curated and prepared data for submission to public relational databases.\n\nCleaned, validated and submitted genomic data to public relational databases NCBI and GenBank.\n\nManaged genomic relational databases (100K+ rows and 10+ tables) and documented data processing and dependencies on GitHub to ensure reproducibility of statistical analyses.\n\nDeveloped and maintained training vignettes to increase team’s data analytics and bioinformatic core competencies in R and Bash to operate in HPC cluster environment and Unix‐like systems.\n\nCommunicated research outcomes to stakeholders and the scientific community by presenting at 4 national and 2 international conferences.\n\nProduct Developer Jan. – May 2024\nConnolly Alexander Institute for Data Science, Tulane University, New Orleans, LA\n\n\nDeveloped and presented a proposal to enhance accessibility to data science tools like Tableau, R, and Python for university students of all skill levels, utilizing public repositories to host shared resources and curricular materials.\n\nCreated and managed a GitHub Pages website for CAIDS, supporting curricular applications and offering accessible resources on data science, including tutorials on version control and introductory R.\n\nLed a team of 10 data research interns to develop data literacy workshops for the broader student body, which grew social media engagement by 150%.\n\nFacilitated and led team dynamics with agile strategies to increase efficiency for the development of workshops and social media strategies.\n\nEnsured transfer of knowledge and increased team core competencies through internal workshops (e.g., introduction to Excel, Intro to Project Management).\n\nAssessed the Data Ambassador Council’s impact on fostering a data-driven community on campus and identified the need for enhanced team-building activities and a structured onboarding process to improve program effectiveness.\n\nCoordinator Jan. 2023 – Jan. 2024\nTulanians Who Enjoy R Coding (TWERC), Tulane University, New Orleans, LA\n\n\nCoordinated the R user group at Tulane University with a membership of approximately 15 - 20 individuals.\n\nFacilitated the development of 4-5 R programming language workshops per semester where students and peers applied coding skills to enhance research methods and tools for academic and professional advancement.\n\nPlayed a pivotal role in informing the state of data science literacy of members to faculty and staff in order to expand official data science programs and course offerings.\n\nData Science Instructor Sept. – Dec. 2023\nHoward-Tilton Memorial Library, Tulane University, New Orleans, LA\n\n\nDeveloped and delivered virtual workshops and training material about version control, data visualization, and R to an audience of 70+ people.\n\nIntroduction to R - 30+ participants.\nIntroduction to Data Visualization in R - 20+ participants.\nIntroduction to Version Control with Git and GitHub - 20+ participants.\n\n\n\nEcological Data Scientist Aug. 2015 – May 2018\nSchool for the Environment and Sustainability, University of Michigan, Ann Arbor, MI\n\n\nLed a team on a 4-month biological sample collection in Mexico; designed experiments, coordinated sample QC, data collection, and exploratory data analyses in R.\n\nApplied GLMMs, ANOVAs, and PERMANOVA analyses to understand interactions of ants and leaf litter nutrients in the tropics; visualized results with “ggplot2” in R.\n\nResults were published in two articles in high-impact, peer-reviewed journals and presented at international conferences."
  },
  {
    "objectID": "cv/index.html#teaching-experience",
    "href": "cv/index.html#teaching-experience",
    "title": "Curriculum Vitae",
    "section": "\n Teaching Experience",
    "text": "Teaching Experience\nTulane University 2018-2024\n\nInstructor Howard-Tilton Memorial Library, Tulane University, New Orleans, LA.\n\n\nOctober 2023 | Introduction to Version Control with Git and GitHub. Developed by B. Aponte Rolón\nOctober 2023 | Introduction to Data Visualization in R. Developed by B. Aponte Rolón .\nOctober 2023 | Introduction to R, Part 1. Developed by Mike Ellis and led by B. Aponte Rolón\nTeaching Assistant Department of Ecology and Evolutionary Biology\n\n\nSpring 2024 & Fall 2018 | Diversity of Life - EBIO 1010. Dr. Jelagat Cheruiyot\nFall 2020 - 2023 & Spring 2019 | Entomology – EBIO 4430/4431. Dr. Jelagat Cheruiyot\nSummer 2023 | Tropical Field Biology - EBIO 3780. Dr. Sunshine Van Bael\nSpring 2023 | Natural History of Louisiana - EBIO 2330. Dr. Donata Henry\nSpring 2023 | Theory and Methods in Ecology and Evolutionary Biology - EBIO 2020. Dr. Donata Henry\nSpring 2022 | Insects and Human Interactions – EBIO 2210. Dr. Jelagat Cheruiyot\nSpring 2021 - Fall 2019 | Plants and Human Affairs – EBIO 3180/3185. Dr. Keith Clay\nSpring 2020 | Plant Biology and Adaptation - EBIO 3590/3591. Dr. Jelagat Cheruiyot\nUniversity of Michigan 2016 - 2017\n\n\nFall 2017 | NRE 509: Ecology: Concepts and Applications. Dr. Sheila K. Schueller\nFall 2016 | ENVIRON 270: Our Common Future. Dr. Ivette Perfecto\nGuest Lectures 2024\n\n\nFall 2024 | BIO 395 Introduction to R Programming for Biologists, Grinnell College"
  },
  {
    "objectID": "cv/index.html#conference-presentations-and-posters",
    "href": "cv/index.html#conference-presentations-and-posters",
    "title": "Curriculum Vitae",
    "section": "\n Conference Presentations and Posters",
    "text": "Conference Presentations and Posters\nAponte Rolón, B. (2025 June). Poster. “From Granite to Meadow: How Host Genetics and Habitat Shape Foliar Endophyte Communities in Monkeyflowers”. Evolution 2025, Athens GA, USA.\nAponte Rolón, B. (2023 June). Oral Presentation: “Foliar fungal symbionts in sympatric yellow monkeyflowers along an elevational gradient”. Evolution 2023, Albuquerque, NM, USA.\nAponte Rolón, B. (2023 March). Poster: “The Influence of host genotype and leaf trait plasticity on foliar fungal endophytes of yellow monkeyflowers in Yosemite National Park, CA”. Collaborators: Kathleen Ferris & Sunshine Van Bael. Tulane Research, Innovation, and Creativity Summit (TRICS), Jung Hotel Grand Hall, New Orleans, LA, USA.\nAponte Rolón, B. (2022 July). Oral Presentation: “Interactions between functional leaf traits and foliar endophytes in the defense against natural enemies of tropical trees” (ID: 358). The 58th Meeting of the Association for Tropical Biology and Conservation (ATBC 2022), Cartagena de Indias, Colombia.\nAponte Rolón, B. (2022 May). Poster: “The Influence of host genotype and leaf trait plasticity on foliar fungal endophytes of yellow monkeyflowers in Yosemite National Park, CA”. Collaborators: Kathleen Ferris & Sunshine Van Bael. Yosemite Symbiosis Workshop. Wawona, CA, USA.\nAponte Rolón, B. (2020 July). Graphical Abstract: “Investigating trade-offs and complementarity between functional leaf traits and foliar endophytic fungi in the defense against plant enemies of tropical woody plants”. Collaborators: A. Elizabeth Arnold, and Sunshine Van Bael. The Mycological Society of America’s First Virtual Meeting, MSA 2020: Mycology from the Cloud (virtual).\nAponte Rolón, B. (2019 May). Poster: “Leaf and Root Endophytes of Mangroves in Southwestern Florida Everglades”. Collaborators: Mareli Sánchez Juliá, Edward Castañeda, John Kominoski, & Sunshine Van Bael. Florida Coastal Everglades LTER All Scientists Meeting. Fairchild Tropical Botanic Garden, Miami, Florida.\nAponte Rolón, B. (2017 October). Poster: “Quality of leaf-litter and ant assemblages in shade-grown coffee in Chiapas, Mexico”, Collaborator: Ivette Perfecto. Student Conference on Conservation Science-New York (SCCS-NY), American Museum of Natural History in New York City, NY, USA.\nAponte Rolón, B. (2017 July). Poster: “Impacts of quality of leaf-litter on ant assemblages in shade-grown coffee in Chiapas, Mexico”, Collaborator: Ivette Perfecto. 54th Annual Meeting of the Association for Tropical Biology and Conservation, “Ecological and Social Dimensions of Tropical Biodiversity Conservation”, Merida, Yucatan, Mexico.\nAponte Rolón, B. (2014 May). Poster: “El efecto del Curcumin en la señalización celular de Artritis Psoriática” [The Effect of Curcumin on cell signaling of Psoriatic Arthritis]. (With Carrero Feliciano, Heysel M.; Hall Laureano, Stephanie; Montes González, Ingrid, PhD.) Annual poster presentation of the American Chemical Society, Puerto Rico Chapter, University of Puerto Rico, Río Piedras Campus, San Juan, Puerto Rico."
  },
  {
    "objectID": "cv/index.html#seminars-workshops",
    "href": "cv/index.html#seminars-workshops",
    "title": "Curriculum Vitae",
    "section": "\n Seminars & Workshops",
    "text": "Seminars & Workshops\nDelegate (Aug. Sept. 2014): “Encuentro latinoamericano y caribeño: asamblea intermedia”. [Intermediate Assembly of the Consejo de Educación Popular de América Latina y el Caribe-CEAAL]. Quito, Ecuador.\nDelegate (October 2013): “Rumbo a la asamblea intermedia”. Sponsored by the Consejo de Educación Popular de América Latina y el Caribe-CEAAL. Santo Domingo, Dominican Republic.\nOrganizer (August 2013): “Primer Encuentro Nacional de Educadores(as) Populares de Puerto Rico”. Sponsored by Consejo de Educación Popular de América Latina y el Caribe-CEAAL, Pontifical Catholic University of Puerto Rico, Ponce, Puerto Rico.\nWorkshop Developer (August 2013): “Educación Popular y Liberación Nacional” [Workshop on Popular Education and National Liberation] Sponsored by La Nueva Escuela at Primer Encuentro Nacional de Educadores(as) Populares de Puerto Rico. Pontifical Catholic University of Puerto Rico, Ponce, Puerto Rico.\nFacilitator & organizer (March 2012): “Sexto Campamento de Jóvenes: Educando para una nueva Patria” [Summit on Popular Education Critical Ideologies, Racism & Xenophobia]. La Nueva Escuela, Peñuelas, Puerto Rico.\nOrganizer (March 2012): “Debates y perspectivas en la construcción de una reforma universitaria inclusiva”. Sponsored by Honors Program Student Association (AEPREH), University of Puerto Rico, Río Piedras Campus. Social Sciences Faculty, University of Puerto Rico, Río Piedras Campus, San Juan Puerto Rico.\nRound table (July 2012): “Puerto Rico: a brief historical account”. Second International Summit “Entre las Crisis y Otros Mundos Posibles” of the Transnational Network of Other Knowledges. Sponsored by Centro de Investigaciones y Estudios Superiores en Antropología Social (CIESAS), CIDECI Las Casas/ UNITIERRA-Chiapas, San Cristóbal de las Casas, Chiapas, México.\nWorkshop Developer (September 2010): “Taller de Educación Popular” [Workshop on Popular Education]. La Nueva Escuela at The University of Puerto Rico, Río Piedras Campus, San Juan, Puerto Rico.\nWorkshop Developer (May 2010): “Taller de Educación Popular y el Movimiento Estudiantil” [Workshop on Popular Education and the Student Movement]. La Nueva Escuela at The University of Puerto Rico, Río Piedras Campus, San Juan, Puerto Rico."
  },
  {
    "objectID": "cv/index.html#grants-and-fellowships",
    "href": "cv/index.html#grants-and-fellowships",
    "title": "Curriculum Vitae",
    "section": "\n Grants and Fellowships",
    "text": "Grants and Fellowships\n\nDepartment of Ecology and Evolutionary Biology2020, 2021, 2022 Tulane University, New Orleans, LA\nStudent Research Grant\nOffice of Graduate and Post-Doctoral Studies2021-2022 Tulane University, New Orleans, LA\nOGPS Fellowship\nRackham Graduate School2017 University of Michigan, Ann Arbor, MI\nRackham International Research Award\nRackham Graduate School2017 University of Michigan, Ann Arbor, MI\nRackham Conference Travel Grant\nRackham Graduate School2015 University of Michigan, Ann Arbor, MI\nRackham Master Fellowship"
  },
  {
    "objectID": "cv/index.html#awards-honors",
    "href": "cv/index.html#awards-honors",
    "title": "Curriculum Vitae",
    "section": "\n Awards & Honors",
    "text": "Awards & Honors\n\n\nExceptional Teaching of an Upper Level Course May 2024\nSteven P. Darwin Outstanding Teaching Assistant AwardTulane University, New Orleans, LA\n\n\nSummer Graduate Award July 2023\nThe Connolly Alexander Institute for Data ScienceTulane University, New Orleans, LA\n\n\nTravel Award May 2022 & 2023\nGraduate Studies Student AssociationTulane University, New Orleans, LA\n\n\nDean’s Travel Award May 2022 & 2023\nSchool of Science and EngineeringTulane University, New Orleans, LA\n\n\nJeffrey Lund Forest Ecology Award April 2017\nSchool for the Environment and SustainabilityUniversity of Michigan, Ann Arbor, MI\n\nAnnual award for academic excellence, research capability, and professional promise."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "CC BY-NC-SA 4.0 license",
    "section": "",
    "text": "© 2025 Bolívar Aponte Rolón\nOpinions expressed are solely my own and do not express the views of my employer or any organizations I am associated with.\nMy content is released under the Creative Commons Attribution-NonCommercial-Sharealike 4.0 International (CC BY-NC-SA) license.\n   \nIn short, you may share and adapt this content with appropriate credit and notation of any changes. You may not use this material for any commercial purposes.\n\n\n\n Back to top"
  },
  {
    "objectID": "scraps/Untitled.html",
    "href": "scraps/Untitled.html",
    "title": "Bolívar Aponte Rolón",
    "section": "",
    "text": "More often than not, the way academics learn R, at least in my experience and among my peers, is through a kind of trial by fire—often fueled by term paper deadlines or the looming pressure of thesis and dissertation submissions. It’s more like learning in the middle of a wildfire, to be honest. Learning R (or any coding tool) takes a backseat to the immediate goal: submitting the paper or presentation abstract. The familiar mantra becomes, “I’ll clean up the code later,” but those end up being famous last words before orphaning a repository, incomplete and messy.\nThis chaotic learning process has predictable pitfalls. From absolute paths breaking code on a different machine to accidentally deleting entire directories and freaking out in meetings when code refuses to run on a colleague’s setup, I’ve seen it all (Jenny Bryan would burn everyone computers). But it was through these frustrations that I began to unlearn bad habits and embrace reproducibility. Unlearning requires constant effort. Tools like version control, renv, .Rproj, and others became liberating. Yes, they require a little more planning at the start of a project, but having code that runs seamlessly on another person’s machine without issue? That’s priceless.\nFor software developers, this might sound like old news, but for many biologists, reproducibility is still an uphill battle. We’re more familiar with the thrill of analyzing data than the discipline of building reproducible environments.\nPersonally, my drive to write and share code comes from an innate need to help others benefit from the little I’ve learned. But more than that, creating rigorous and reproducible science isn’t just an academic exercise; it’s a moral compass. My journey didn’t stem from learning best practices. As a trained ecologist and evolutionary biologist (EEB), R and computational tools were primarily a means to answer the big questions in my field. But what really pushed me to dive deeper was frustration—specifically, with how knowledge is often transferred in academia.\n\n\n\n Back to top"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Bolívar Aponte Rolón, PhD",
    "section": "",
    "text": "Data scientist ← c(“ecologist”, “evolutionary biologist”)\nBroadly, I apply statistical and machine learning methods, linear modeling, and modern workflow practices to genomic and ecological data. Curious about what I’m working on? Explore recent projects and methods on my Research page.\n\n\n\n\nI am a data scientist and bioinformatician that focuses on translating research insights into open, reproducible tools that others can build upon and use to do publishable science.\nMy scholarship sits at the intersection of statistical modeling, research software engineering, and microbial community ecology. To that end, I develop reproducible analytical pipelines in R and Python to analyze amplicon and whole‑genome sequencing data, uncovering how microbial symbionts interact with their plant hosts, from tropical trees to alpine yellow monkeyflowers. I integrate sequencing outputs with ecological context, focusing on community assembly, host associations, and environmental drivers in high‑dimensional datasets. Most recently, I help build cross‑institutional workflows with containerized environments to standardize microbiome analyses across bioenergy feedstocks. My focus is translating complex datasets into clear, shareable results that others can reproduce, reuse, and build upon.\nOpen, transparent, and reproducible science guides my work. I prioritize community standards and reproducibility, whether developing R packages for core‑microbiome analysis or contributing to ESIP’s data stewardship initiatives to advance best practices in data management. Additionally, I share practical skills in data visualization, wrangling, and analysis through workshops and tutorials.\nGet in touch!"
  },
  {
    "objectID": "about/index.html#thanks-for-visiting-my-website",
    "href": "about/index.html#thanks-for-visiting-my-website",
    "title": "Bolívar Aponte Rolón, PhD",
    "section": "",
    "text": "Data scientist ← c(“ecologist”, “evolutionary biologist”)\nBroadly, I apply statistical and machine learning methods, linear modeling, and modern workflow practices to genomic and ecological data. Curious about what I’m working on? Explore recent projects and methods on my Research page."
  },
  {
    "objectID": "about/index.html#about-me",
    "href": "about/index.html#about-me",
    "title": "Bolívar Aponte Rolón, PhD",
    "section": "",
    "text": "I am a data scientist and bioinformatician that focuses on translating research insights into open, reproducible tools that others can build upon and use to do publishable science.\nMy scholarship sits at the intersection of statistical modeling, research software engineering, and microbial community ecology. To that end, I develop reproducible analytical pipelines in R and Python to analyze amplicon and whole‑genome sequencing data, uncovering how microbial symbionts interact with their plant hosts, from tropical trees to alpine yellow monkeyflowers. I integrate sequencing outputs with ecological context, focusing on community assembly, host associations, and environmental drivers in high‑dimensional datasets. Most recently, I help build cross‑institutional workflows with containerized environments to standardize microbiome analyses across bioenergy feedstocks. My focus is translating complex datasets into clear, shareable results that others can reproduce, reuse, and build upon.\nOpen, transparent, and reproducible science guides my work. I prioritize community standards and reproducibility, whether developing R packages for core‑microbiome analysis or contributing to ESIP’s data stewardship initiatives to advance best practices in data management. Additionally, I share practical skills in data visualization, wrangling, and analysis through workshops and tutorials.\nGet in touch!"
  },
  {
    "objectID": "coc.html",
    "href": "coc.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "I value kindness and inclusivity. This means I will:\n\nbe friendly, courteous, and respectful\ntake great care to not make statements that could cause offence, personal hurt, or discourage participation/conversation\n\nI am putting putting myself in a vulnerable position by posting content to the very public wild web. I hope others, no matter their experience level, feel comfortable enough to participate in discussions in the spirit of learning out loud.\nI will not post unacceptable content, and I will delete any references or comments that contain it.\nI define unacceptable content as anything included or linked to that:\n\nis being used to abuse, harass, stalk, or threaten others\nis libelous, knowingly false, ad-hominem, or misrepresents another person\ninfringes upon a copyright or trademark\nviolates an obligation of confidentiality\nviolates the privacy of others\n\nI define and determine what is “unacceptable content” on a case-by-case basis, and my definitions are not limited to this list. If I delete a comment or link, I will say so and explain why. I reserve the right to change these standards at any time with no notice.\nModified from Jadey Ryan, modified it from Cédric Scherer, who modified from Tim O’Reilly.\n\n\n\n Back to top"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Experiment freely, learn endlessly",
    "section": "",
    "text": "Flexible R Setup on Linux\n\n\n\nR\n\nLinux\n\nOpenBLAS\n\nComputer Science\n\n\n\n\n\n\nNov 11, 2024\n\n\nBolívar Aponte Rolón\n\n\n\n\n\n\n\n\n\n\n\n\nLoop Less, Do More: Iterating Efficiently with purrr\n\n\n\nR\n\ntidyverse\n\npurrr\n\n\n\n\n\n\nOct 21, 2024\n\n\nBolívar Aponte Rolón\n\n\n\n\n\nNo matching items\n Back to topReuseCC BY-SA 4.0"
  },
  {
    "objectID": "blog/2024-10-15-map_purrr/index.html",
    "href": "blog/2024-10-15-map_purrr/index.html",
    "title": "Loop Less, Do More: Iterating Efficiently with purrr\n",
    "section": "",
    "text": "For the past couple of years, I’ve been deepening my understanding of R—its ecosystem and the many tools it offers for supporting open and reproducible science. Lately, I’ve been participating in the Programming in R course by Posit Academy and learning functional programming concepts, which I highly recommend even if you’re a seasoned useR. This has prompted me to refactor much of the code I’ve produce to be more maintainable and human. My main focus has been plot reproduction. Some of my code has hundreds of lines producing ggplots that can easily be turned into a function(s). This is where the purrr package comes in."
  },
  {
    "objectID": "blog/2024-10-15-map_purrr/index.html#what-have-i-learned",
    "href": "blog/2024-10-15-map_purrr/index.html#what-have-i-learned",
    "title": "Loop Less, Do More: Iterating Efficiently with purrr\n",
    "section": "What have I learned?",
    "text": "What have I learned?\nLet’s see some example of how to use purr::map() to automate plot generation.\nSetup\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\nThe tidyverse meta package includes ggplot (plots generation), purrr (iteration), and dplyr (data wrangling) the three main packages we will be using. ### The problem\nCopy and paste code to produce plots.\n\n# Afghanistan\ngapminder |&gt;\n  filter(country == \"Afghanistan\" ) |&gt;\nggplot(aes(x = year, y = lifeExp)) +\n  geom_jitter(position = position_jitter(width = 0.1, height = 0), alpha = 1) +\n  geom_smooth(method = lm, se = T, level = 0.95, na.rm = F) +\n  labs(title = \"Afghanistan\")\n\n\n\n\n\n\n# United States\ngapminder |&gt;\n  filter(country == \"United States\" ) |&gt;\n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_jitter(position = position_jitter(width = 0.1, height = 0), alpha = 1) +\n  geom_smooth(method = lm, se = T, level = 0.95, na.rm = F) +\n  labs(title = \"United States\")\n\n\n\n\n\n\n# United Kingdom\ngapminder |&gt;\n  filter(country == \"United Kingdom\" ) |&gt;\n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_jitter(position = position_jitter(width = 0.1, height = 0), alpha = 1) +\n  geom_smooth(method = lm, se = T, level = 0.95, na.rm = F) +\n  labs(title = \"United Kingdom\")\n\n\n\n\n\n\n# China\ngapminder |&gt;\n  filter(country == \"China\" ) |&gt;\n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_jitter(position = position_jitter(width = 0.1, height = 0), alpha = 1) +\n  geom_smooth(method = lm, se = T, level = 0.95, na.rm = F) +\n  labs(title = \"China\")\n\n\n\n\n\n\n# India\ngapminder |&gt;\n  filter(country == \"India\" ) |&gt;\n  ggplot(aes(x = year, y = lifeExp)) +\n  geom_jitter(position = position_jitter(width = 0.1, height = 0), alpha = 1) +\n  geom_smooth(method = lm, se = T, level = 0.95, na.rm = F) +\n  labs(title = \"India\")\n\n\n\n\n\n\n\nFive plots might not be a big deal. But it quickly becomes a hassle to keep track of when you have over a dozen variables and the plots are roughly the same that it’s not worth writing a whole new chunk. I’ve omitted creating respective object for the plots, but that is how I would usually store them and call them throughout the analysis (e.g., us_scatter or something like that). The issue with this approach is that it is prone to a lot of error. Copying and pasting, then tweaking the code ever so slightly is a major source of human error (e.g. forgetting to change the x variable). Again, its manageable now, but not with bigger projects."
  },
  {
    "objectID": "blog/2024-10-15-map_purrr/index.html#how-do-we-automate-this",
    "href": "blog/2024-10-15-map_purrr/index.html#how-do-we-automate-this",
    "title": "Loop Less, Do More: Iterating Efficiently with purrr\n",
    "section": "How do we automate this?",
    "text": "How do we automate this?\nFirst, let’s write a function\n\nlm_ggplot &lt;- function(data, .country, x, y) {\ndata |&gt;\n    filter(country == {{.country}} ) |&gt;\n    ggplot(aes(x = {{x}}, y = {{y}})) +\n    geom_jitter(position = position_jitter(width = 0.1, height = 0), alpha = 1) +\n    geom_smooth(method = lm, se = T, level = 0.95, na.rm = F) +\n    labs(title = .country)\n}\n\nLet’s test our function\n\nlm_ggplot(gapminder, .country = \"Afghanistan\", x = year, y = lifeExp)\n\n\n\n\n\n\n\nGreat! Our function has the desired output and we can now use it to automate the plot generation.\n\ncountries &lt;- c(\"Afghanistan\", \"United States\", \"United Kingdom\", \"China\", \"India\")\n\nmap(countries, \\(.x) lm_ggplot(data = gapminder, .country = .x, x = year, y = lifeExp))\n\n[[1]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nWe are able to generate the sample plot for all countries with far fewer lines of code. We have effectively, iterated over the countries vector and applied the lm_ggplot function to each element. This is a simple example, but the power of purrr is that it can be used to iterate over any object that can be iterated over (e.g., lists, dataframes, etc.)."
  },
  {
    "objectID": "blog/2024-10-15-map_purrr/index.html#how-does-map-work",
    "href": "blog/2024-10-15-map_purrr/index.html#how-does-map-work",
    "title": "Loop Less, Do More: Iterating Efficiently with purrr\n",
    "section": "How does map() work?",
    "text": "How does map() work?\nmap() is a function that takes two arguments:\nmap(v, .fun)\na vector or list and a function. The function is applied to each element of the vector or list. It is specialized to iterate over and return vectors and lists.\nThe way I used map() here is with the syntax usually used for anonymous functions. The \\.x is a shorthand for the first argument of the function. in this case, it is were the vectors of countries will be passed to to iterate over."
  },
  {
    "objectID": "blog/2024-10-15-map_purrr/index.html#behold-the-list-column",
    "href": "blog/2024-10-15-map_purrr/index.html#behold-the-list-column",
    "title": "Loop Less, Do More: Iterating Efficiently with purrr\n",
    "section": "Behold, the list column\n",
    "text": "Behold, the list column\n\nWhen we work with R work are working with object that are atomic vectors of different types (e.g., character, numerical, integers, floats, etc.). One of the most powerful data structures in R are lists. Lists are a collection of objects that can be of any type. This makes them very flexible and powerful. We can have a list of data frames (which are list themselves), plots, functions, etc. In this exercise, map() returned a list of ggplots. Now one of the most useful things I have learned lately is the list columns.\nList columns are a column in a data frame that contains a list. This is allows us to store multiple objects in a single column. Having a list column within a data frame or by it self can help us reduce the number of intermediate object that we create within a project. Instead of creating an object for each plot or linear models, we can store them in a list column in a single object that we can access and use throughout our analyses.\nLet’s see how lists columns work. We are going to use nest() to summarize grouped data by nesting the non-grouping variables into a list column of data frames—one data frame per group.\n\nlife_expectancy &lt;-\n  gapminder |&gt; \n  select(country, continent, year, lifeExp) |&gt; \n  group_by(country, continent) |&gt; \n  nest()\n\nlife_expectancy\n\n# A tibble: 142 × 3\n# Groups:   country, continent [142]\n   country     continent data             \n   &lt;fct&gt;       &lt;fct&gt;     &lt;list&gt;           \n 1 Afghanistan Asia      &lt;tibble [12 × 2]&gt;\n 2 Albania     Europe    &lt;tibble [12 × 2]&gt;\n 3 Algeria     Africa    &lt;tibble [12 × 2]&gt;\n 4 Angola      Africa    &lt;tibble [12 × 2]&gt;\n 5 Argentina   Americas  &lt;tibble [12 × 2]&gt;\n 6 Australia   Oceania   &lt;tibble [12 × 2]&gt;\n 7 Austria     Europe    &lt;tibble [12 × 2]&gt;\n 8 Bahrain     Asia      &lt;tibble [12 × 2]&gt;\n 9 Bangladesh  Asia      &lt;tibble [12 × 2]&gt;\n10 Belgium     Europe    &lt;tibble [12 × 2]&gt;\n# ℹ 132 more rows\n\n\nNow we have a data frame with column data that contains a list of data frames. We can use map() to apply a function to each element of the list column.\nLet’s define some useful functions to fit a linear model, plot the data, and predict life expectancy in 2030.\n\n# Functions to fit a linear model, plot the data, and predict life expectancy in 2030\nfit_pop &lt;- function(df) {\n  lm(pop ~ year, data = df)\n}\n\nplot_pop &lt;- function(df) {\n  ggplot(df, aes(x = year, y = pop)) +\n    geom_point() +\n    geom_smooth(method = lm)\n}\n\npred_pop &lt;- function(mod) {\n  input &lt;- tibble(year = 2030)\n  predict(mod, newdata = input)\n}\n\nNow we can use map() to apply these functions to each data frame in the list column.\n\n# Fit a linear model to each data frame in the list column\ngap_list_df &lt;- gapminder |&gt; \n  select(country, year, pop) |&gt; \n  group_by(country) |&gt; \n  nest() |&gt; \n  mutate(\n    model = map(data, fit_pop),\n    plot = map(data, plot_pop),\n    pop_2030 = map_dbl(model, pred_pop)\n  )\n\ngap_list_df\n\n# A tibble: 142 × 5\n# Groups:   country [142]\n   country     data              model  plot     pop_2030\n   &lt;fct&gt;       &lt;list&gt;            &lt;list&gt; &lt;list&gt;      &lt;dbl&gt;\n 1 Afghanistan &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;    33846451.\n 2 Albania     &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;     4879306.\n 3 Algeria     &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;    43758285.\n 4 Angola      &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;    14598072.\n 5 Argentina   &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;    49706374.\n 6 Australia   &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;    25613532.\n 7 Austria     &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;     8784507.\n 8 Bahrain     &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;      956764.\n 9 Bangladesh  &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;   187136396.\n10 Belgium     &lt;tibble [12 × 2]&gt; &lt;lm&gt;   &lt;gg&gt;    11138373.\n# ℹ 132 more rows\n\n\nFor each country we have a group data frame within data column, a linear model in model column, and a ggplot in plot column. We can access it like this:\n\n# Afghanistan data frame\ngap_list_df$data[[1]]\n\n# A tibble: 12 × 2\n    year      pop\n   &lt;int&gt;    &lt;int&gt;\n 1  1952  8425333\n 2  1957  9240934\n 3  1962 10267083\n 4  1967 11537966\n 5  1972 13079460\n 6  1977 14880372\n 7  1982 12881816\n 8  1987 13867957\n 9  1992 16317921\n10  1997 22227415\n11  2002 25268405\n12  2007 31889923\n\n# Afghanistan linear model\ngap_list_df$model[[1]]\n\n\nCall:\nlm(formula = pop ~ year, data = df)\n\nCoefficients:\n(Intercept)         year  \n -690631821       356886  \n\n# Afghanistan ggplot\ngap_list_df$plot[[1]]\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n# Afghanistan predicted population in 2030\ngap_list_df$pop_2030[[1]]\n\n[1] 33846451\n\n\nWith one object we can access all the information we need for each country. We can include this in reports and analyses."
  },
  {
    "objectID": "blog/2024-10-15-map_purrr/index.html#conclusion",
    "href": "blog/2024-10-15-map_purrr/index.html#conclusion",
    "title": "Loop Less, Do More: Iterating Efficiently with purrr\n",
    "section": "Conclusion",
    "text": "Conclusion\nThese are some of the ways I’ve been using purrr to automate my plots and analyses. I hope you find this useful and that it helps you in your work. I highly recommend you check out the R for Data Science book by Hadley Wickham and Garrett Grolemund. It is a great resource for learning the tidyverse and purrr."
  },
  {
    "objectID": "blog/2024-10-15-map_purrr/index.html#references",
    "href": "blog/2024-10-15-map_purrr/index.html#references",
    "title": "Loop Less, Do More: Iterating Efficiently with purrr\n",
    "section": "References",
    "text": "References\n\nR for Data Science\nGapminder vignette\nCode Smells and Feels\nEfficiency and Consistency: Automate Subset Graphics with ggplot2 and purrr"
  },
  {
    "objectID": "blog/2024-11-11-flexible_r/index.html",
    "href": "blog/2024-11-11-flexible_r/index.html",
    "title": "Flexible R Setup on Linux",
    "section": "",
    "text": "Achieving reproducible results, whether working with full analytical pipelines or simple analyses, is contingent on the specific software used and the underlying environment. Often times, we need to reproduce experimental results or need to use packages that are no longer being maintained. With R, this is easily achieved through some combination of Conda virtual environments, renv and Docker images. This is often considered the epitome of reproducibility. However, sometimes it just doesn’t merit setting up a whole environment to work on a small project, therefore having multiple versions of R in the base environment might be desirable to speed things up. The process of setting up different R versions in the base environment, accessed through RStudio, depends on your operating system:"
  },
  {
    "objectID": "blog/2024-11-11-flexible_r/index.html#lets-get-into-it",
    "href": "blog/2024-11-11-flexible_r/index.html#lets-get-into-it",
    "title": "Flexible R Setup on Linux",
    "section": "Let’s get into it",
    "text": "Let’s get into it\nWe’ll install R from source with two different configurations and learn how to switch between versions. See the R installation guide for more options.\n\nInternal BLAS: Uses R’s internal shared BLAS library (libRblas.so) for simplicity and modularity.\nOpenBLAS: Links R to system-optimized OpenBLAS and LAPACK libraries for performance gains.\nHow to switch between R versions: Changing environment variables to choose our R versions.\n\nBoth configurations include the shared R library (libR.so), which is important for compatibility with external applications like RStudio."
  },
  {
    "objectID": "blog/2024-11-11-flexible_r/index.html#configuration-1-using-rs-internal-shared-blas-library",
    "href": "blog/2024-11-11-flexible_r/index.html#configuration-1-using-rs-internal-shared-blas-library",
    "title": "Flexible R Setup on Linux",
    "section": "Configuration 1: Using R’s Internal Shared BLAS Library",
    "text": "Configuration 1: Using R’s Internal Shared BLAS Library\nThis configuration uses R’s internal BLAS library (libRblas.so) by building it as a shared library. It is straightforward and avoids external dependencies, ensuring compatibility across various setups. Although this configuration may lack some of the performance optimizations provided by OpenBLAS, it is ideal for general usage and stable builds.\n\n\nPrerequisites\nInstall the necessary build dependencies:\nsudo pacman -S base-devel gcc-fortran blas lapack\nDownload and extract the R source code from CRAN:\nwget https://cran.r-project.org/src/base/R-4/R-4.4.2.tar.gz  \ntar -xzvf R-4.4.2.tar.gz  \ncd R-4.4.2\nFor this tutorial I installed R 4.4.1 and 4.4.2, which are not really that different but the same steps apply to any version.\n\n\n\nConfigure\nRun the following command to configure R with its internal shared BLAS:\n./configure --prefix=/opt/R/$(cat VERSION) --enable-R-shlib --enable-BLAS-shlib\n\nExplanation of Flags\n\n--prefix=/opt/R/$(cat VERSION): Installs R in a versioned directory under /opt/R, allowing multiple R versions to coexist (e.g., /opt/R/4.4.2).\n--enable-R-shlib: Builds the shared R library libR.so, which is required for integration with RStudio.\n--enable-BLAS-shlib: Builds R’s internal BLAS library (libRblas.so) as a shared library.\n\n\n\n\n\n\n\nNote\n\n\n\nThe configure script to build R from source has many more options. Be sure to check those out and tailor your installation to your needs.\n\n\n\n\n\nVerification after ./configure\nThis is the last bit .configure outputs when finished:\n R is now configured for x86_64-pc-linux-gnu  \n  \n Source directory:            .  \n Installation directory:      /opt/R/4.4.2  \n  \n C compiler:                  gcc  -g -O2  \n Fortran fixed-form compiler: gfortran  -g -O2  \n  \n Default C++ compiler:        g++ -std=gnu++17  -g -O2  \n C++11 compiler:              g++ -std=gnu++11  -g -O2  \n C++14 compiler:              g++ -std=gnu++14  -g -O2  \n C++17 compiler:              g++ -std=gnu++17  -g -O2  \n C++20 compiler:              g++ -std=gnu++20  -g -O2  \n C++23 compiler:              g++ -std=gnu++23  -g -O2  \n Fortran free-form compiler:  gfortran  -g -O2  \n Obj-C compiler:                  \n  \n Interfaces supported:        X11, tcltk  \n External libraries:          pcre2, readline, curl, libdeflate  \n Additional capabilities:     PNG, JPEG, TIFF, NLS, cairo, ICU  \n Options enabled:             shared R library, shared BLAS, R profiling, libdeflate for lazyload  \n  \n Capabilities skipped:           \n Options not enabled:         memory profiling  \n  \n Recommended packages:        yes\n\n\nBuilding and Installing R\nOnce configured, compile and install R:\nmake -j$(nproc) # Setting to number cores to speed up a little bit\nsudo make install\nAfter installation, run the following to check R’s configuration:\nR  sessionInfo()\nR version 4.4.2 (2024-10-31)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Arch Linux\n\nMatrix products: default\nBLAS:   /opt/R/4.4.2/lib64/R/lib/libRblas.so # Built shared BLAS library\nLAPACK: /usr/lib/liblapack.so.3.12.0 # System LAPACK library\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8   \n [6] LC_MESSAGES=C.UTF-8    LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           LC_TELEPHONE=C        \n[11] LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\ntime zone: America/Chicago\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n[1] compiler_4.4.2 tools_4.4.2\nI’ve used this install configuration for almost every data science project I’ve tackled. It is minimal and ready for general usage.\nWhat if we want better performance? Let’s set it up with OpenBLAS and get some speed. Checkout some of the benchmarks mentioned in this GitHub repo , here, and also here\n\nSpeed Racer Go Time GIFfrom Speed Racer GIFs"
  },
  {
    "objectID": "blog/2024-11-11-flexible_r/index.html#configuration-2-linking-to-system-optimized-openblas-and-lapack",
    "href": "blog/2024-11-11-flexible_r/index.html#configuration-2-linking-to-system-optimized-openblas-and-lapack",
    "title": "Flexible R Setup on Linux",
    "section": "Configuration 2: Linking to System-Optimized OpenBLAS and LAPACK",
    "text": "Configuration 2: Linking to System-Optimized OpenBLAS and LAPACK\nHere, we want to link R to the system’s OpenBLAS and LAPACK libraries, which are optimized for performance and multi-threading. It is ideal for high-performance linear algebra operations. The way to achieve this is by explicitly requesting the libraries using the --with-blas and --with-lapack. Find more details in this old R installation guide and the upcoming R guide.\n\nPrerequisites\nInstall the necessary build dependencies:\nsudo pacman -S base-devel gcc-fortran openblas lapack\n\n\n\n\n\n\nWarning\n\n\n\nThe main difference here is that we install openblas. It shouldn’t have any conflict with blas, if it does you might want to build from source in /opt as well.\n\n\nDownload and extract the R source code from CRAN:\nwget https://cran.r-project.org/src/base/R-4/R-4.4.2.tar.gz  \ntar -xzvf R-4.4.2.tar.gz  \ncd R-4.4.2\nWe need to check where the BLAS and LAPACK library symlinks and executables are located:\nls -ld /usr/lib/liblapack* /usr/lib/libopenblas*\nI prefer to link the libraries by providing the absolute path. It is also possible to give a name without a path (like -lfoo) and the linker will look for a library file named libfoo.so (or libfoo.a for a static library) in standard library directories. See BLAS configuration guide.\n\n\n\n\n\n\nNote\n\n\n\nUse the executablesliblapack.so.* and libopenblas.so.*. If you have color coding in your terminal it will be a slightly brighter green, see below.\n\n\n\n\n\n\n\n\n\nNote on blas-openblas and 64-Bit Integer Library Support\n\n\n\nYou can link to the bundled BLAS and LAPACK libraries provided by blas-openblas using the --with-blas flag.\nImportant: The blas-openblas library conflicts with blas. Since it provides BLAS/CBLAS/LAPACK/LAPACKE system-wide, any packages that depend on these libraries will need to be rebuilt. For this reason, building from source in a dedicated directory is recommended.\nThe blas64-openblas library does not create conflicts and can be particularly beneficial for handling large datasets or complex scientific computations. By supporting 64-bit indexing, blas64-openblas enables larger matrix operations, making it ideal for intensive data processing.\n\n\n\n\nInstalling R with openblas\nRun the following command to configure R with OpenBLAS and LAPACK:\n./configure --prefix=/opt/R/$(cat VERSION) \\\n            --enable-R-shlib \\\n            --with-blas=\"/usr/lib/libopenblas.so.0.3\" \\\n            --with-lapack=\"/usr/lib/liblapack.so.3.12.0\"\n\nFlags used\n\n--prefix=/opt/R/$(cat VERSION): Installs R in a versioned directory under /opt/R, as in Configuration 1.\n--enable-R-shlib: Builds libR.so, the shared R library.\n--with-blas=\"/usr/lib/libopenblas.so.0.3\": Links R to the system’s OpenBLAS library for optimized BLAS routines.\n--with-lapack=\"/usr/lib/liblapack.so.3.12.0\": Links R to the system’s LAPACK library, providing optimized higher-level matrix operations.\n\n\n\nConfiguration output\nR is now configured for x86_64-pc-linux-gnu  \n  \n Source directory:            .  \n Installation directory:      /opt/R/4.4.2  \n  \n C compiler:                  gcc  -g -O2  \n Fortran fixed-form compiler: gfortran  -g -O2  \n  \n Default C++ compiler:        g++ -std=gnu++17  -g -O2  \n C++11 compiler:              g++ -std=gnu++11  -g -O2  \n C++14 compiler:              g++ -std=gnu++14  -g -O2  \n C++17 compiler:              g++ -std=gnu++17  -g -O2  \n C++20 compiler:              g++ -std=gnu++20  -g -O2  \n C++23 compiler:              g++ -std=gnu++23  -g -O2  \n Fortran free-form compiler:  gfortran  -g -O2  \n Obj-C compiler:                  \n  \n Interfaces supported:        X11, tcltk  \n External libraries:          pcre2, readline, BLAS(generic), LAPACK(generic), curl, libdeflate  \n Additional capabilities:     PNG, JPEG, TIFF, NLS, cairo, ICU  \n Options enabled:             shared R library, R profiling, libdeflate for lazyload  \n  \n Capabilities skipped:           \n Options not enabled:         shared BLAS, memory profiling  \n  \n Recommended packages:        yes\nNotice BLAS(generic), LAPACK(generic), indicating the use of the system’s libraries.\n\n\nBuilding and installing R\nOnce configured with the above command, compile and install R:\nmake -j$(nproc) \nsudo make install\nLike before, we run the following to check R’s configuration:\nR sessionInfo()\nYour output should look like this:\nR version 4.4.2 (2024-10-31)  \nPlatform: x86_64-pc-linux-gnu  \nRunning under: Arch Linux  \n  \nMatrix products: default  \nBLAS/LAPACK: /usr/lib/libopenblas.so.0.3;  LAPACK version 3.12.0  \n  \nlocale:  \n[1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8          \n[4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8      \n[7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C             \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C      \n  \ntime zone: America/Chicago  \ntzcode source: system (glibc)  \n  \nattached base packages:  \n[1] stats     graphics  grDevices utils     datasets  methods   base        \n  \nloaded via a namespace (and not attached):  \n[1] compiler_4.4.\nNotice the linked openblas library in BLAS/LAPACK , in comparison to when we use --enable-BLAS-shlib only. OpenBLAS typically includes LAPACK routines as part of the library, so R is effectively using the LAPACK routines within OpenBLAS, which is compatible with LAPACK version 3.12.0."
  },
  {
    "objectID": "blog/2024-11-11-flexible_r/index.html#benefits-of-using-system-optimized-blaslapack",
    "href": "blog/2024-11-11-flexible_r/index.html#benefits-of-using-system-optimized-blaslapack",
    "title": "Flexible R Setup on Linux",
    "section": "Benefits of Using System-Optimized BLAS/LAPACK",
    "text": "Benefits of Using System-Optimized BLAS/LAPACK\nBy linking R to system-provided OpenBLAS and LAPACK libraries, we improved performance in numerical operations. Well, I haven’t performed a benchmark of my own but I trust that it is a little faster. We should expect:\n\nPerformance Gains:\n\nOpenBLAS is highly optimized for operations such as matrix multiplications, dot products, and other foundational linear algebra tasks. It can significantly speed up computations in R, especially for functions that rely heavily on these operations (e.g., matrix decompositions, linear regression, and large-scale simulations).\nLAPACK complements BLAS by providing higher-level mathematical functions, such as eigenvalue decompositions, singular value decompositions (SVD), and other advanced matrix operations. LAPACK routines calls BLAS to perform complex computations, thus reducing computation time for common data science, statistical modeling, and machine learning operations.\n\nMulti-threading Support:\n\nOpenBLAS is designed to take advantage of multi-core CPUs, (with some caveats), making it ideal for computations that benefit from parallel processing. By linking R to OpenBLAS, R can automatically utilize multiple cores for matrix and linear algebra computations, significantly reducing computation times on multi-threaded operations.\n\nArchitecture-Specific Optimizations:\n\nOpenBLAS and LAPACK are frequently optimized for specific CPU architectures (e.g., Intel, AMD) and can take advantage of processor-specific instructions like Advanced Vector Extensions (AVX) and Streaming SIMD Extensions (SSE). This means that R can achieve better performance on compatible hardware, albeit contingent on the underlying architecture, compared to using its internal BLAS/LAPACK libraries.\n\n\nWe could conduct benchmarks to measure how much computation time has improved, but that’s beyond our scope for now. To compare different R versions, I need to switch between them. So, how do we go about doing that?"
  },
  {
    "objectID": "blog/2024-11-11-flexible_r/index.html#how-to-switch-between-r-versions",
    "href": "blog/2024-11-11-flexible_r/index.html#how-to-switch-between-r-versions",
    "title": "Flexible R Setup on Linux",
    "section": "How to switch between R versions",
    "text": "How to switch between R versions\nAll that effort is impressive but it loses its value if it comes with friction. On Windows and Mac, toggling between R versions is straightforward, as I mentioned earlier. However, Linux users often face more challenges. Fortunately, the community has developed several solutions to streamline this process.\nI found a nifty shim written by Jeff Keller to toggle between R versions. It’s a shell script to set the environment variable R_VERSION to the preferred version and then launch R Studio.\nI echo his script here with some modifications of my own."
  },
  {
    "objectID": "blog/2024-11-11-flexible_r/index.html#toggle-shim",
    "href": "blog/2024-11-11-flexible_r/index.html#toggle-shim",
    "title": "Flexible R Setup on Linux",
    "section": "Toggle Shim",
    "text": "Toggle Shim\nAs a root, replace the R and Rscript binaries found in /bin/R/ and /bin/Rscript.\ncat &lt;&lt; 'EOF'  /bin/R\n#!/bin/bash\n&lt;&lt;prelude\nShim from https://jeff.vtkellers.com/posts/data-science/managing-multiple-r-installations-on-linux/\nused to toggle between R versions installed in /opt/R\nprelude\n\n# Uncomment this to set a fixed default version of R. Otherwise, the\n# most recent version will be used.\nR_VERSION_DEFAULT=\"4.4.1\"\n\n# The default installation directory is /opt/R (https://docs.rstudio.com/resources/install-r/)\n# Change this as is necessary for your environment.\nR_INSTALL_DIR=\"/opt/R\"\n\n\n\nR_VERSIONS_AVAIL=($(basename --multiple $(dirname $(dirname $(ls \"${R_INSTALL_DIR}\"/*/bin/R))) | sort --version-sort))\n\n# If no default R version is set then set the most recent version as the default\nif [ -z ${R_VERSION_DEFAULT} ]; then\n  R_VERSION_DEFAULT=\"${R_VERSIONS_AVAIL[-1]}\"\nfi\n\n# If a specific R version was not requested then use the default\nif [ -z ${R_VERSION} ]; then\n  R_VERSION=\"${R_VERSION_DEFAULT}\"\nfi\n\nR_BINARY_BASE=$(basename $0)\nR_BINARY=\"${R_INSTALL_DIR}/${R_VERSION}/bin/${R_BINARY_BASE}\"\n\nif [ ! -f $R_BINARY ]; then\n  echo \"${R_BINARY_BASE} ${R_VERSION} not found. Available versions: ${R_VERSIONS_AVAIL[*]}\"\n  exit 1\nfi\n\n# Unset the R_HOME env var if something else set it\nunset R_HOME\n\"${R_BINARY}\" \"$@\"\nEOF\nChanging /bin/R/ should result in changes in /usr/bin/R. You can double check before proceeding. I fixed my default version of R but you can comment to set to the latest R version.\nMake the script executable:\nchmod +x /bin/R\nCreate a Symlink to Rscript\nln -s /bin/R /bin/Rscript\n\nUsage\nexport R_VERSION=4.4.1\nrstudio &"
  },
  {
    "objectID": "blog/2024-11-11-flexible_r/index.html#conclusions",
    "href": "blog/2024-11-11-flexible_r/index.html#conclusions",
    "title": "Flexible R Setup on Linux",
    "section": "Conclusions",
    "text": "Conclusions\nWe’ve installed different versions of R and learned how to switch between them. This flexibility can help us experiment with different analyses and projects. The toggling shim is an excellent solution for launching RStudio with your preferred R version. However, I encountered an issue when opening R projects (.Rproj files). Regardless of the R version specified for the project, it always loads the latest installed version of R. Additionally, setting the R_VERSION environment variable does not affect which R version the project uses. This means that even if your project was created with an different version of R, it will still open with an unintended latest version in /opt/R.\nA practical workaround I found is to launch RStudio with the desired R version first, then switch to the intended project using the toggle in the upper right corner. See green arrow below.\n\nIt’s not a frictionless solution but it’s not too bad once you’ve incorporated it in your workflow. For now, it will do. I’ll slowly make improvements to see if I can get it working with projects.\n\nI hope this helps out folks wanting to have various versions of R and easily switch between them. Please let me know if you have any comments of suggestions."
  },
  {
    "objectID": "blog/2024-11-11-flexible_r/index.html#additional-resources",
    "href": "blog/2024-11-11-flexible_r/index.html#additional-resources",
    "title": "Flexible R Setup on Linux",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nOfficial Documentation\n\nInstalling Multiple Versions of R on Linux\nComprehensive guide from Posit on how to install and manage multiple R versions on Linux systems.\nChanging R Versions for the RStudio Desktop IDE\nInstructions on how to switch between different R versions within the RStudio IDE.\nR Administration Manual\nOfficial R documentation detailing configurations.\n\n\n\nCommunity Discussions\n\nR with LAPACK from OpenBLAS - Posit Forum\nA forum thread discussing the integration of LAPACK from OpenBLAS in R.\nFaster BLAS in R - Brett Klamer’s Blog\nBlog post exploring methods to speed up BLAS operations in R.\n\n\n\nTutorials and Guides\n\nR Performance with BLAS - csantill.github.io\nA detailed tutorial on optimizing R performance using BLAS libraries.\nWhy is R Slow? Explanations and MKL/OpenBLAS Setup to Fix It\nAn R-bloggers article explaining common performance issues in R and how to address them with MKL/OpenBLAS.\nManaging Multiple R Installations on Linux\nMonica Thieu’s Post on Managing Multiple R Versions\nInsights and solutions from the community on handling multiple R versions.\n\n\n\nTools and Repositories\n\nr-blas GitHub Repository\nGitHub repository for managing BLAS configurations in R."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bolívar Aponte Rolón, Ph.D.",
    "section": "",
    "text": "I am a data scientist, bioinformatician, and research software engineer with a background in ecology and evolutionary biology.\nLearn more about me →\n\n    \n    \n  \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contact/index.html",
    "href": "contact/index.html",
    "title": "Bolívar Aponte Rolón",
    "section": "",
    "text": "Feel free to reach out if you have any questions, want to collaborate, or just want to chat about science and data.\n  \n\n\n\n\n\n\n\n\nFull Name \nEmail Address \nMessage\n\n\nSend message"
  },
  {
    "objectID": "contact/index.html#send-me-a-note",
    "href": "contact/index.html#send-me-a-note",
    "title": "Bolívar Aponte Rolón",
    "section": "",
    "text": "Feel free to reach out if you have any questions, want to collaborate, or just want to chat about science and data."
  },
  {
    "objectID": "accessibility.html",
    "href": "accessibility.html",
    "title": "Accessibility commitment",
    "section": "",
    "text": "I am fairly new to web design and development, but I am committed to making my website as accessible as possible.\nThis accessibility commitment was adapted from Jadey Ryan which modified it from Silvia Canelón’s commitment."
  },
  {
    "objectID": "accessibility.html#feedback",
    "href": "accessibility.html#feedback",
    "title": "Accessibility commitment",
    "section": "Feedback",
    "text": "Feedback\nI welcome any feedback on the accessibility and inclusivity of my site and content. Please let me know if you encounter any accessibility barriers or areas for improvement and I’ll do my best to incorporate them."
  },
  {
    "objectID": "accessibility.html#accessibility-practices",
    "href": "accessibility.html#accessibility-practices",
    "title": "Accessibility commitment",
    "section": "Accessibility practices",
    "text": "Accessibility practices\nThis site has been designed with the following features in mind:\n\nA color palette that meets WCAG 2.1 AA standards for contrast.\nAlternative text for all informative images.\nReadable font faces, specifically to avoid impostor letter shapes and mirroring.\n\nEach character in [iIl], [ceo], and [db qp] should all be distinct from one another.1\nThis site primarily uses Baskervville SC and Raleway for headings, Nunito Sans for body text, and Fira Code for code.\n\nA table of contents in the sidebars for easier navigation."
  },
  {
    "objectID": "accessibility.html#accessibility-tools",
    "href": "accessibility.html#accessibility-tools",
    "title": "Accessibility commitment",
    "section": "Accessibility tools",
    "text": "Accessibility tools\nI use the following to best inform my accessibility practices:\n\nGoogle Lighthouse Tool\nGoogle Chrome Accessibility Features Reference\nColour Contrast Checker\nViz Palette\nWAVE Web Accessibility Evaluation Tool\nMicrosoft Edge Accessibility Guide"
  },
  {
    "objectID": "accessibility.html#footnotes",
    "href": "accessibility.html#footnotes",
    "title": "Accessibility commitment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAdded the [ceo] and [db qp] tests from Cara Thompson’s amazing data viz design system talk, specifically slide 22: Font inspiration.↩︎"
  },
  {
    "objectID": "Untitled.html",
    "href": "Untitled.html",
    "title": "Bolívar Aponte Rolón",
    "section": "",
    "text": "Mission\n\nHelp website developers plan, structure, and deliver clear, scalable, and performant websites by defining information architecture, content models, and reusable content patterns that align with brand, SEO, and accessibility goals.\n\nCore Competencies\n\nInformation Architecture (IA): sitemaps, navigation models, taxonomy, URL strategy\nContent Strategy: audience/intent mapping, content briefs, page templates, editorial workflows\nContent Modeling: reusable components, schemas, content types, governance\nSEO and Discoverability: keyword mapping, internal linking, schema.org, Open Graph/Twitter cards\nAccessibility and Quality: WCAG 2.2 AA, inclusive language, reading-level and readability checks\nPerformance and UX: Core Web Vitals-friendly content, media strategy, layout/content trade-offs\n\nExpertise Areas\n\nStatic and content-driven sites: Quarto, Hugo, Jekyll, Astro, Next.js (content layer)\nDesign systems and CSS architecture: utility-first or BEM/ITCSS, tokens, component inventories\nCMS-agnostic content patterns; workflows for Contentful/Sanity/Netlify CMS/Git-based content\nAnalytics-informed content: GA4/events, privacy-friendly analytics, A/B testing\nTechnical SEO: sitemaps/robots, redirects, canonicalization, hreflang/i18n\nDocumentation and knowledge bases: versioned docs, changelogs, release notes\n\nKey Skills\n\nHTML and CSS/SCSS; semantic markup and structured data\nQuarto and Bootstrap for docs/sites; pattern library alignment\nCopywriting and editing for clarity, consistency, and brand voice\nContent migration planning: audits, gap analysis, redirects, link integrity\nGovernance: editorial calendars, roles/ownership, review checklists\n\nContext Awareness\n\nUnderstands NGS/data-heavy workflows and can translate technical/scientific material into web-ready content when needed\nFamiliar with tidyverse-style reproducibility and can align docs/content pipelines with dev workflows\nIf relevant, can leverage background in ecology/bioinformatics to shape accurate scientific content and visuals\n\nOperating Principles\n\nStructure-first: define IA and content models before visual polish or optimization\nReuse and maintainability: prefer components, patterns, and single sources of truth\nAccessibility by default; performance-aware content choices\nExplain trade-offs (complexity vs. scalability, SEO vs. UX, editorial speed vs. governance)\nMeasurable outcomes: tie changes to KPIs (engagement, conversions, documentation task success)\n\nInteraction Style\n\nAsks diagnostic questions before proposing solutions\nProvides clear artifacts (sitemaps, templates, briefs) and phased plans\nDocuments rationale and trade-offs; suggests quick wins and longer-term improvements\nAvoids premature optimization; iterates based on analytics and feedback\n\nDefault Deliverables\n\nSitemap and navigation model with taxonomy and URL conventions\nContent types and schemas (fields, validation, relationships) + example entries\nPage templates and wireframe-level content outlines (hero, messaging, CTAs, modules)\nSEO briefs per page type: keywords, headings, metadata, internal links, schema\nEditorial workflow: roles, review steps, quality checklist, accessibility checks\nMigration and redirects plan; broken link and media optimization checklist\n\nQuality and Accessibility Standards\n\nWCAG 2.2 AA, semantic HTML, focus management, alt text policy\nCore Web Vitals-conscious content (image sizing, lazy-loading guidance, copy length/layout)\nSchema.org for key entities (Organization, Article, FAQ, Product, Dataset as applicable)\nInternationalization readiness (copy length variance, date/number formats, hreflang)\n\nTooling Preferences and Formats\n\nWorks with Git-based content, PR-driven reviews, and CI checks (links, Lighthouse, spelling/grammar)\nDelivers artifacts as Markdown or JSON/YAML (for content models), and editable sitemaps\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "Theobroma cacao leaves consumed by leaf cutter ants\n\n\n\n\n\nGraphical abstract of ecological interactions\n\n\n\n\n\n\nFlowering plants are adept at developing strategies to ward of enemies, including establishing important symbioses with other organisms, such as fungi that live within their tissues (endophytes), to tackle challenges like warding off enemies. In the tropics, insect herbivores and fungal pathogens are plentiful. Yet, with all these enemies around, woody plants are highly diverse and thrive. In combination with plant’s leaf functional traits, could diverse endophytes that naturally infect seedlings provide benefits against natural enemies?\nWe developed an experiment where we reared 7 tropical tree species in a greenhouse and then inoculated them naturally with fungal spores from a nearby forest. Having tree seedlings with low and high levels of endophytes, we presented leaves to leaf-cutter ants (insect herbivore) and tested how much of the leaf they harvested in a determined period. We also exposed tree seedling to a generalist pathogen and measured how much damage the pathogen caused.\nOur findings highlight the complex dynamics of plant-herbivore-pathogen relationships and underscore the importance of endophytes as a potentially low-cost, preemptive defense strategy for plants, especially during early growth stages. These insights not shed light on the nuanced role of endophytes in plant ecology.\nCollaborators:\n\nA. Elizabeth Arnold\nMareli Sánchez Juliá\nSunshine A. Van Bael\n\nSee publication here"
  },
  {
    "objectID": "research/index.html#fungal-endophytes-and-natural-enemies",
    "href": "research/index.html#fungal-endophytes-and-natural-enemies",
    "title": "Research",
    "section": "",
    "text": "Theobroma cacao leaves consumed by leaf cutter ants\n\n\n\n\n\nGraphical abstract of ecological interactions\n\n\n\n\n\n\nFlowering plants are adept at developing strategies to ward of enemies, including establishing important symbioses with other organisms, such as fungi that live within their tissues (endophytes), to tackle challenges like warding off enemies. In the tropics, insect herbivores and fungal pathogens are plentiful. Yet, with all these enemies around, woody plants are highly diverse and thrive. In combination with plant’s leaf functional traits, could diverse endophytes that naturally infect seedlings provide benefits against natural enemies?\nWe developed an experiment where we reared 7 tropical tree species in a greenhouse and then inoculated them naturally with fungal spores from a nearby forest. Having tree seedlings with low and high levels of endophytes, we presented leaves to leaf-cutter ants (insect herbivore) and tested how much of the leaf they harvested in a determined period. We also exposed tree seedling to a generalist pathogen and measured how much damage the pathogen caused.\nOur findings highlight the complex dynamics of plant-herbivore-pathogen relationships and underscore the importance of endophytes as a potentially low-cost, preemptive defense strategy for plants, especially during early growth stages. These insights not shed light on the nuanced role of endophytes in plant ecology.\nCollaborators:\n\nA. Elizabeth Arnold\nMareli Sánchez Juliá\nSunshine A. Van Bael\n\nSee publication here"
  },
  {
    "objectID": "research/index.html#fungal-endophytes-and-yellow-monkeyflowers",
    "href": "research/index.html#fungal-endophytes-and-yellow-monkeyflowers",
    "title": "Research",
    "section": "Fungal Endophytes and Yellow Monkeyflowers",
    "text": "Fungal Endophytes and Yellow Monkeyflowers\n\n\n\n\nFoliar Endophytes in yellow monkeyflowers along elevation gradients in the Sierra Nevada (in-process)\nMicrobes play crucial roles in plant health and adaptation, but their distribution is influenced by environmental conditions, geographic distance, and plant species. Fungi have helped plants colonize various climates, but little is known about how plant microbiomes affect local adaptation.\nThis study focused on foliar endophytic fungi (FEF), which can help plants survive stressful conditions like drought. We explored how FEF communities in Mimulus species (monkeyflowers) vary with elevation and interact with leaf traits. Mimulus species, found in diverse habitats from dry outcrops to alpine meadows, offer an ideal system to study plant-microbe interactions.\nUsing genetic sequencing, we examined how FEF communities change across three Mimulus species in the Sierra Nevada mountains, revealing insights into how these fungi respond to environmental conditions and host leaf traits.\nCollaborators:\n\nCaroline M. Dong\nKathleen G. Ferris\nSunshine A. Van Bael\n\n\n\n\n\n\n\nMimulus guttatus field in Stanislaus National Forest\n\n\n\n\n\n\n\n\n\n\n\n\nCommon garden experiment in granite outcrop at Yosemite National Park\n\n\n\n\n\nGenotype and phenotype interactions with foliar fungal symbionts in common gardens (in-process)\nIn the face of climate change, to survive, plants rely on both genetic changes and their ability to adapt to changing environments. We know that plants form beneficial partnerships with fungi and bacteria, however the role of these microbes in helping plants adapt to their environments is less understood. Building on previous findings, this research tests how foliar endophytic fungi (FEF) respond to host leaf traits in a reciprocal transplant experiment. By crossing M. guttatus and M. laciniatus and obtaining F2 hybrids we aim to understand the contributions of host plant genetics and phenotype, and the environment to FEF community composition.\nOur results may shed light on how plants and their microbial partners work together to adapt to diverse and challenging environments. By exploring how fungi help plants respond to different environmental stresses (planted in the other species environment: meadows and granite outcrops), we can better predict how plant species might cope with the rapid changes in climate, offering insights into plant survival and biodiversity conservation.\nCollaborators:\n\nCaroline M. Dong\nKathleen G. Ferris\nSunshine A. Van Bael\n\n\n\n\n\n\nLab innovation\nThe process of capturing fungal endophytes from yellow monkeyflower tissue led to innovations in DNA extraction and PCR setup. See below:\n\nAponte Rolón, B. (2023). High-Molecular-Weight SPRI-aided DNA extraction from Mimulus (Phrymaceae) leaf tissue. dx.doi.org/10.17504/protocols.io.bp2l6xn8rlqe/v2"
  }
]